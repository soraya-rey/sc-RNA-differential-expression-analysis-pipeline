Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	1	differential_expression
	1	integrate_samples
	4	preprocess_sample
	7

[Tue Nov  5 00:39:12 2024]
rule preprocess_sample:
    input: data/SCD2/matrix.mtx, data/SCD2/features.tsv, data/SCD2/barcodes.tsv
    output: results/SCD2/processed_seurat_object.rds
    jobid: 6
    wildcards: sample=SCD2

[Tue Nov  5 00:39:12 2024]
Error in rule preprocess_sample:
    jobid: 6
    output: results/SCD2/processed_seurat_object.rds

RuleException:
CalledProcessError in line 19 of /home/utilisateur/Bureau/single_cell_DEG/Snakefile:
Command 'set -euo pipefail;  Rscript --vanilla /home/utilisateur/Bureau/single_cell_DEG/.snakemake/scripts/tmptulgpsf3.preprocess_sample.R' returned non-zero exit status 1.
  File "/home/utilisateur/Bureau/single_cell_DEG/Snakefile", line 19, in __rule_preprocess_sample
  File "/usr/lib/python3.8/concurrent/futures/thread.py", line 57, in run
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/utilisateur/Bureau/single_cell_DEG/.snakemake/log/2024-11-05T003911.984749.snakemake.log
